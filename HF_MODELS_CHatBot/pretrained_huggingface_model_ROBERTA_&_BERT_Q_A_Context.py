# -*- coding: utf-8 -*-
"""PreTrained_HuggingFace_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HyVLvCmEZ1xYpVZD5zEYDRSsfR8Juz19

#Using Pretrained 'deepset/roberta-base-squad2' of HuggingFace Model

##Import and install libraries
"""

!pip install torch transformers

#import libraries
import torch # Pytorch is import for handling tensors outputs and the AutoModelForQuestionAnswering class from Hugging Face Transformers is based on PyTorch
from transformers import AutoModelForQuestionAnswering , AutoTokenizer, pipeline  # huggingface transformers and related libraries that make our task easy

"""##Model And Transformer Install"""

#uncomment any model_name you wanna test/use

# model_name = 'deepset/roberta-base-squad2'
model_name = 'bert-base-uncased'

model =AutoModelForQuestionAnswering.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

"""#Test How This Works"""

#dummy question and context to checck how this works
question = "How can I manage my anger effectively?"
context = "Managing anger effectively involves recognizing triggers, practicing relaxation techniques, and communicating assertively rather than aggressively."

"""## without pipeline

More control and flexibility, but requires more manual steps. Useful for customization.Like by showing the details of tokenization, model inference, and decoding
"""

input = tokenizer(question, context, return_tensors="pt") #tokenizing the input (question and context)
output = model(**input) #passing input to model

print(output)

# convert numbers/tensors to text

answer_start_idx = torch.argmax(output.start_logits)  # start position of answer in context predicted by model
answer_end_idx = torch.argmax(output.end_logits)  # end position of answer in context predicted by model

answer_tokens = input.input_ids[0,answer_start_idx: answer_end_idx +1] #extracting answer_tokens from context using positions model predicted (answer_start_idx and answer_end_idx)
answer = tokenizer.decode(answer_tokens) # converting numbers to text by using decode method

print("ques: {}\nanswer: {}".format(question, answer)) # print question along with answer

"""##Method2- pipeline

 Simplifies the process with less code (abstracts away the details of tokenization, model inference, and decoding) , making it convenient and user-friendly for standard tasks.
"""

qa = pipeline('question-answering', model = model_name, tokenizer=model_name)  # initializing pipeline for Q/A task and specifying model and tokenizer
output = qa(question, context) # passing input as question and context

print(output) #showing output

print(output['answer']) # extract only answer from output

"""#Q/A For Empathetic ChatBot
####PROVIDING CONTEXT CONTAINIG AN EMPATHETIC ASSISTANT LIKE ANSWER/TEXT
"""

# Variable to contain context from which model would answer our questions, related to mental health or depression related issue with empathy

document = """
Understanding Depression and Bullying:
Feeling depressed due to bullying or similar issues is a serious concern. Bullying can have a profound impact on mental health, leading to feelings of sadness, loneliness, and low self-esteem. It's important to recognize the signs and seek support.

Impact of Bullying on Mental Health:
Bullying can cause significant emotional distress and may lead to symptoms of depression, such as:
- Persistent sadness or tearfulness
- Social withdrawal and isolation
- Loss of interest in activities once enjoyed
- Changes in sleep or appetite patterns
- Feelings of worthlessness or hopelessness
- Thoughts of self-harm or suicide

Empathetic Support and Coping Strategies:
Empathetic support is crucial for individuals experiencing bullying-related depression:
- Acknowledge Feelings: Validating the person's emotions and reassuring them that their feelings are understandable.
- Encourage Open Communication: Creating a safe space for them to express their thoughts and concerns without fear of judgment.
- Provide Coping Strategies: Techniques like mindfulness, relaxation exercises, and talking to a trusted adult or counselor can help manage stress and build resilience.
- Address Safety Concerns: Ensuring the individual's safety and taking steps to address the bullying situation through school authorities or other appropriate channels.

Seeking Professional Help:
It's important to seek professional help if feelings of depression persist or worsen:
- Therapy and Counseling: Professional therapists can provide strategies to cope with bullying-related stress and improve overall well-being.
- Support Groups: Joining support groups with peers who have similar experiences can provide understanding and encouragement.
- Crisis Intervention: Immediate support is available through crisis hotlines and emergency mental health services.

Promoting Resilience and Self-Care:
Building resilience and practicing self-care are essential:
- Building a Support Network: Surrounding oneself with supportive friends and family members can provide emotional strength.
- Setting Boundaries: Learning to assert boundaries and avoid situations that may exacerbate stress or negative emotions.
- Self-Care Practices: Engaging in activities that promote relaxation and self-compassion, such as hobbies, exercise, and adequate sleep.

Encouraging Open Dialogue:
Encouraging open dialogue about bullying and its impact helps reduce stigma and promotes understanding. By fostering empathy and providing resources, we can support those affected by bullying-related depression and help them on their path to recovery.
"""

"""**DIFFERENCE BETWEEN PIPELINE AND WITHOUT PIPELINE APPROACH :**

**Non-Pipeline:** More control and flexibility, but requires more manual steps. Useful for customization.

**Pipeline:** Simplifies the process with less code, making it convenient and user-friendly for standard tasks.

##WITHOUT PIPELINE
"""

while True:
    # Take user question as input
    user_question = input("Please enter your question (or type 'exit' to quit): ")
    if user_question.lower() == 'exit':
        break

    # Tokenize the input question with the common context
    inputs = tokenizer(user_question, document, return_tensors="pt")
    outputs = model(**inputs)

    # Find the start and end indices of the answer
    answer_start_idx = torch.argmax(outputs.start_logits)
    answer_end_idx = torch.argmax(outputs.end_logits)

    # Decode the answer tokens
    answer_tokens = inputs.input_ids[0, answer_start_idx: answer_end_idx + 1]
    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)

    # Print the question and answer
    print("\n [Q] :{} \n [A]: {}".format(user_question, answer),'\n')

"""**some questions to test**

I feel really down because I'm being bullied at school. What should I do?

How does bullying affect mental health?

What are some signs that bullying is causing depression?

Can talking to someone help me feel better about being bullied?

What are some coping strategies for dealing with bullying-related depression?

## USING HUGGING FACE TRANSFORMER'S PIPELINE
"""

# Load the question-answering pipeline
qa = pipeline('question-answering', model=model_name, tokenizer=model_name)


def answer_question(user_question, context):
    # Prepare the input for the QA model
    qa_input = {
        'question': user_question,
        'context': context
    }
    # Get the answer from the QA model
    answer = qa(qa_input)
    return answer

# Example usage
user_question = input("Please enter your question: ")
context = document  # Use the predefined document as context

output = answer_question(user_question, context)
print('[A]', output['answer'])

"""Few test questions"""

user_question = input("Please enter your question: ")
context = document  # Using the predefined document as context

output = answer_question(user_question, context)
print('[A]', output['answer'])

user_question = input("Please enter your question: ")
context = document

output = answer_question(user_question, context)
print('[A]', output['answer'])

user_question = input("Please enter your question: \n")
context = document

output = answer_question(user_question, context)
print('[A]', output['answer'])